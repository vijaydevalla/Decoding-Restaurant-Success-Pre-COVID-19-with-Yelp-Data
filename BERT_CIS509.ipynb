{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "dfduJgNkYRNI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "26976831-8048-4a94-f274-e4acbf37ec5d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.37.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.13.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.19.3 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.20.3)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.25.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2023.12.25)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.31.0)\n",
            "Requirement already satisfied: tokenizers<0.19,>=0.14 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.15.2)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.2)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.2)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (2023.6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (4.9.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2024.2.2)\n"
          ]
        }
      ],
      "source": [
        "# Mount Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Install Transformers library\n",
        "!pip install transformers"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load the dataset\n",
        "df = pd.read_csv('/content/drive/My Drive/Restaurants_Data_2018.csv')\n",
        "\n",
        "# Drop unnecessary columns\n",
        "df = df[['text', 'name', 'is_open']]\n",
        "\n",
        "# Group reviews by restaurant name\n",
        "grouped_reviews = df.groupby('name')['text'].apply(lambda x: ' '.join(x)).reset_index()\n",
        "\n",
        "# Merge with is_open column\n",
        "grouped_data = grouped_reviews.merge(df[['name', 'is_open']], on='name').drop_duplicates()\n",
        "\n",
        "# Convert is_open to binary labels\n",
        "grouped_data['is_open'] = grouped_data['is_open'].astype(int)\n"
      ],
      "metadata": {
        "id": "S2BJLNtUYTCk"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Split the dataset into train and test sets\n",
        "train_texts, test_texts, train_labels, test_labels = train_test_split(grouped_data['text'],\n",
        "                                                                      grouped_data['is_open'],\n",
        "                                                                      test_size=0.2,\n",
        "                                                                      random_state=42)"
      ],
      "metadata": {
        "id": "EXKfyOfrYWjz"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import BertTokenizer\n",
        "\n",
        "# Load BERT tokenizer\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
        "\n",
        "# Tokenize text data\n",
        "train_encodings = tokenizer(train_texts.tolist(), truncation=True, padding=True)\n",
        "test_encodings = tokenizer(test_texts.tolist(), truncation=True, padding=True)\n"
      ],
      "metadata": {
        "id": "iDZfqT2sYZAz"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "# Convert labels to TensorFlow dataset\n",
        "train_dataset = tf.data.Dataset.from_tensor_slices((dict(train_encodings), train_labels))\n",
        "test_dataset = tf.data.Dataset.from_tensor_slices((dict(test_encodings), test_labels))\n"
      ],
      "metadata": {
        "id": "j_nLXnTvYbqF"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "learning_rates = [ 0.00002, 0.000002]\n",
        "accuracies = []\n",
        "\n",
        "for lr in learning_rates:\n",
        "    # Fine-tune BERT model\n",
        "    model = TFBertForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=2)\n",
        "\n",
        "    # Using Adam optimizer with specified learning rate\n",
        "    optimizer = tf.keras.optimizers.Adam(learning_rate=lr)\n",
        "\n",
        "    # Using sparse categorical cross-entropy loss function\n",
        "    loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)  # Sparse categorical cross-entropy loss function\n",
        "\n",
        "    metrics = ['accuracy']\n",
        "    model.compile(optimizer=optimizer, loss=loss, metrics=metrics)\n",
        "\n",
        "    # Fine-tune the model on the downstream task\n",
        "    history = model.fit(train_dataset.shuffle(1000).batch(8), epochs=3, batch_size=8, verbose=0)\n",
        "\n",
        "    # Evaluate the model\n",
        "    test_loss, test_accuracy = model.evaluate(test_dataset.batch(16), verbose=0)\n",
        "    accuracies.append(test_accuracy)\n",
        "\n",
        "# Print accuracies for each learning rate\n",
        "for lr, acc in zip(learning_rates, accuracies):\n",
        "    print(f'Learning Rate: {lr}, Test Accuracy: {acc}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J5m79pMxpBpI",
        "outputId": "696aa58b-f6a1-416a-9e93-ca75e4543264"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "All PyTorch model weights were used when initializing TFBertForSequenceClassification.\n",
            "\n",
            "Some weights or buffers of the TF 2.0 model TFBertForSequenceClassification were not initialized from the PyTorch model and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "All PyTorch model weights were used when initializing TFBertForSequenceClassification.\n",
            "\n",
            "Some weights or buffers of the TF 2.0 model TFBertForSequenceClassification were not initialized from the PyTorch model and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Learning Rate: 2e-05, Test Accuracy: 0.7401574850082397\n",
            "Learning Rate: 2e-06, Test Accuracy: 0.7401574850082397\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate the model\n",
        "test_loss, test_accuracy = model.evaluate(test_dataset.batch(8), verbose=2)\n",
        "print(f'Test Accuracy: {test_accuracy}')\n"
      ],
      "metadata": {
        "id": "THoqfsZ0Yf6n",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f7ea6c2b-ed2d-4ebf-b1b5-962427f962f7"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "16/16 - 5s - loss: 0.5571 - accuracy: 0.7402 - 5s/epoch - 339ms/step\n",
            "Test Accuracy: 0.7401574850082397\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Optionally, save the model for future use\n",
        "# model.save_pretrained('/content/drive/My Drive/bert_model')\n"
      ],
      "metadata": {
        "id": "i17Sst0SYmhA"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "# Make predictions\n",
        "predictions = model.predict(test_dataset.batch(16))\n",
        "predicted_labels = np.argmax(predictions.logits, axis=1)\n",
        "\n",
        "# Generate classification report\n",
        "print(classification_report(test_labels, predicted_labels))\n"
      ],
      "metadata": {
        "id": "WoKdOHHyYsSh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ae3358ea-ec01-4e98-d6b8-7428bdbba058"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "8/8 [==============================] - 8s 678ms/step\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00        33\n",
            "           1       0.74      1.00      0.85        94\n",
            "\n",
            "    accuracy                           0.74       127\n",
            "   macro avg       0.37      0.50      0.43       127\n",
            "weighted avg       0.55      0.74      0.63       127\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%shell\n",
        "jupyter nbconvert --to html /content/LA5_Tyagi_Upmanyu.ipynb"
      ],
      "metadata": {
        "id": "hOjhoVWf5_J1"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}